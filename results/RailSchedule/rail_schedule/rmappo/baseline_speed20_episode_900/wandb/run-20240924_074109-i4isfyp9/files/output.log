observation_space [Box(9,), Box(9,), Box(9,)]
share_observation_space [Box(27,), Box(27,), Box(27,)]
obs_space:  [Box(9,), Box(9,), Box(9,)]
share_obs_space:  [Box(27,), Box(27,), Box(27,)]
act_space:  Discrete(3)
Traceback (most recent call last):
  File "main.py", line 135, in <module>
    main(sys.argv[1:])
  File "main.py", line 120, in main
    runner.run()
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/runner/rail_runner.py", line 40, in run
    train_infos = self.train()
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/runner/base_runner.py", line 120, in train
    train_infos = self.trainer.train(self.buffer)
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/algorithms/r_mappo.py", line 218, in train
    = self.ppo_update(sample, update_actor)
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/algorithms/r_mappo.py", line 125, in ppo_update
    values, action_log_probs, dist_entropy = self.policy.evaluate_actions(share_obs_batch,
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/algorithms/rMAPPOPolicy.py", line 108, in evaluate_actions
    values, _ = self.critic(cent_obs, rnn_states_critic, masks)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/algorithms/r_actor_critic.py", line 170, in forward
    critic_features = self.base(cent_obs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/algorithms/utils/mlp.py", line 51, in forward
    x = self.mlp(x)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chunhuili/Transportation/RailEnvironment/MAPPO/algorithms/utils/mlp.py", line 24, in forward
    x = self.fc2[i](x)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 104, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/chunhuili/anaconda3/envs/transport/lib/python3.8/site-packages/torch/nn/functional.py", line 1500, in relu
    result = torch.relu(input)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 23.60 GiB of which 18.19 MiB is free. Process 3244606 has 20.51 GiB memory in use. Process 3261667 has 1.16 GiB memory in use. Process 3280804 has 1.16 GiB memory in use. Including non-PyTorch memory, this process has 750.00 MiB memory in use. Of the allocated memory 409.48 MiB is allocated by PyTorch, and 32.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
